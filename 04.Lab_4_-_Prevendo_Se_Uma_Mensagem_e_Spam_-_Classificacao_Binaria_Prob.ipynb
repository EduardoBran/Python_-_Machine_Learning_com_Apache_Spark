{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45aad633",
   "metadata": {},
   "source": [
    "<span style=\"color: green; font-size: 40px; font-weight: bold;\">Lab 4 (Classificação Binária Probabilística) </span>\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "# Prevendo Se Uma Mensagem de Texto é Spam\n",
    "\n",
    "<br>\n",
    "\n",
    "### Contexto\n",
    "\n",
    "Neste projeto, abordaremos um problema comum em sistemas de comunicação digital: a **detecção de mensagens de texto indesejadas, conhecidas como spam**. Com o aumento do uso de mensagens eletrônicas, a capacidade de distinguir automaticamente entre mensagens legítimas e spam se tornou essencial para manter a integridade e a usabilidade dos serviços de mensagens. O objetivo deste projeto é desenvolver um modelo preditivo que, baseado no conteúdo textual das mensagens, consiga identificar se uma mensagem é spam ou não. Utilizaremos técnicas de Machine Learning para criar um modelo de classificação binária probabilística, capaz de fornecer uma previsão acompanhada de uma estimativa de probabilidade.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "O objetivo deste projeto é **construir um modelo de Machine Learning capaz de prever se uma mensagem de texto é spam**. O modelo será treinado utilizando dados históricos de mensagens rotuladas como \"spam\" ou \"ham\" (não spam), permitindo que ele faça previsões sobre novas mensagens com base em padrões aprendidos.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Pergunta de Negócio Principal\n",
    "\n",
    "> \"Como podemos prever se uma mensagem de texto é spam utilizando seu conteúdo textual?\"\n",
    "\n",
    "<br>\n",
    "\n",
    "### Entregável\n",
    "\n",
    "O entregável deste projeto será um **modelo de Machine Learning treinado para identificar mensagens de texto como spam ou não**. O modelo será capaz de classificar novas mensagens e fornecer a probabilidade associada a cada previsão. O processo de desenvolvimento incluirá a preparação dos dados, a seleção de features relevantes, o treinamento do modelo e a avaliação de seu desempenho.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sobre o Conjunto de Dados\n",
    "\n",
    "Os dados utilizados neste projeto contêm uma coleção de mensagens de texto classificadas manualmente como \"spam\" ou \"ham\". Cada entrada do conjunto de dados inclui o texto da mensagem e sua respectiva classificação. Utilizaremos esse conjunto para treinar e validar nosso modelo.\n",
    "\n",
    "<br>\n",
    "<table border=\"2\">\n",
    "  <tr>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Nome da Coluna</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Tipo de Dado</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Descrição</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>label</td>\n",
    "    <td>string</td>\n",
    "    <td>Classificação da mensagem (ham para não spam, spam para mensagens indesejadas).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>message</td>\n",
    "    <td>string</td>\n",
    "    <td>Conteúdo textual da mensagem.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IDF, HashingTF, Tokenizer\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985b686",
   "metadata": {},
   "source": [
    "<br> <br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 38px; font-weight: bold;\">Preparando o Ambiente Spark</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo semente aleatória (seed) para reprodutibilidade do notebook\n",
    "rnd_seed = 23\n",
    "np.random.seed = rnd_seed\n",
    "np.random.set_state = rnd_seed\n",
    "\n",
    "# Se houver uma sessão Spark ativa, encerre-a\n",
    "if 'sc' in globals():\n",
    "    sc.stop()\n",
    "\n",
    "if 'spark' in globals():\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "# Criando o Spark Context\n",
    "conf = SparkConf().setAppName(\"Lab4\") \\\n",
    "                  .set(\"spark.ui.showConsoleProgress\", \"false\") \\\n",
    "                  .set(\"spark.executor.heartbeatInterval\", \"20s\") \\\n",
    "                  .set(\"spark.eventLog.enabled\", \"false\") \\\n",
    "                  .set(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "                  .set(\"spark.sql.debug.maxToStringFields\", \"100\") \\\n",
    "                  .set(\"spark.executor.memory\", \"4g\") \\\n",
    "                  .set(\"spark.driver.memory\", \"4g\") \\\n",
    "                  .set(\"spark.driver.maxResultSize\", \"2g\")  # Configuração adicional para limitar o tamanho do resultado\n",
    "\n",
    "# Criar o Spark Context e a Spark Session\n",
    "sc = SparkContext(conf=conf)\n",
    "spSession = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Ajustar o nível de log para ERROR\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Configurar log4j para suprimir avisos (deixar como comentário e volta ao normal)\n",
    "log4j_logger = sc._jvm.org.apache.log4j\n",
    "log4j_logger.LogManager.getLogger(\"org\").setLevel(log4j_logger.Level.ERROR)\n",
    "log4j_logger.LogManager.getLogger(\"akka\").setLevel(log4j_logger.Level.ERROR)\n",
    "\n",
    "# Visualizar o objeto spark_session\n",
    "spSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb531be",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 38px; font-weight: bold;\">Carregando os Dados</span>\n",
    "\n",
    "- Os dados serão carregados a partir de um arquivo CSV e gerados como um RDD (Resilient Distributed Dataset) no Apache Spark. O RDD é uma estrutura de dados distribuída que permite o processamento paralelo em um cluster, otimizando a performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados e gerando um RDD\n",
    "spamRDD = sc.textFile(\"Lab/dados/dataset3.csv\")\n",
    "\n",
    "# Tipo\n",
    "print(type(spamRDD), '\\n')\n",
    "\n",
    "# Colocando o RDD em cache. Esse processo otimiza a performance\n",
    "print(spamRDD.cache(), '\\n')\n",
    "\n",
    "# Número de registros\n",
    "print(spamRDD.count(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as primeiras linhas\n",
    "print(spamRDD.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b679fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizando primeiras 4 linhas com Pandas (Apenas para visualização)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Obter as primeiras 5 linhas do RDD\n",
    "linhas = spamRDD.take(5)\n",
    "\n",
    "# Dividir as linhas em colunas utilizando o ponto-e-vírgula como delimitador\n",
    "colunas = linhas[0].split(\";\")\n",
    "dados_formatados = [linha.split(\";\") for linha in linhas[1:]]\n",
    "\n",
    "# Criar um DataFrame Pandas com as colunas e os dados formatados\n",
    "df = pd.DataFrame(dados_formatados, columns=colunas)\n",
    "\n",
    "# Mostrar o DataFrame\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7328d1",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 38px; font-weight: bold;\"> Análise Exploratória Inicial dos Dados </span>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criação de Função Para Análise Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def funcao_analise_inicial(df):\n",
    "    # Configurar Pandas para exibir todas as linhas\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    # Informações do DataFrame\n",
    "    print('\\n\\n INFO \\n\\n')\n",
    "    df.info()\n",
    "    print('\\n\\n ------------------------------------------------------------------------------------------ \\n\\n')\n",
    "\n",
    "    # Verifica se há valores ausentes e duplicados\n",
    "    valores_ausentes = df.isna().sum().sum() > 0\n",
    "    valores_duplicados = df.duplicated().sum() > 0\n",
    "\n",
    "    # Nomes das variáveis com valores ausentes\n",
    "    variaveis_ausentes = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "    # Número de linhas duplicadas\n",
    "    num_linhas_duplicadas = df.duplicated().sum()\n",
    "\n",
    "    # Porcentagem de linhas duplicadas\n",
    "    porcentagem_linhas_duplicadas = (num_linhas_duplicadas / len(df)) * 100\n",
    "\n",
    "    # Exibe o resultado sobre valores ausentes e duplicados\n",
    "    print(\"\\n\\nExistem valores ausentes:\", valores_ausentes)\n",
    "    if valores_ausentes:\n",
    "        print(\"\\nVariáveis com valores ausentes:\", variaveis_ausentes)\n",
    "    else:\n",
    "        print(\"\\nNenhuma variável possui valores ausentes.\")\n",
    "\n",
    "    print(\"\\n\\nExistem valores duplicados:\", valores_duplicados)\n",
    "    if valores_duplicados:\n",
    "        print(\"\\nNúmero de Linhas Duplicadas:\", num_linhas_duplicadas)\n",
    "        print(\"\\nPorcentagem de Linhas Duplicadas: {:.2f}%\".format(porcentagem_linhas_duplicadas))\n",
    "    else:\n",
    "        print(\"\\nNenhuma variável possui valores duplicados.\")\n",
    "    \n",
    "    # Verificação de caracteres especiais\n",
    "    caracteres_especiais = re.compile('[@_!#$%^&*<>()?/\\\\|}{~:]')   # nenhum caracter removido\n",
    "    colunas_com_caracteres_especiais = {}\n",
    "\n",
    "    for coluna in df.columns:\n",
    "        if df[coluna].dtype == 'object':  # Verifica apenas colunas de texto\n",
    "            contem_caracteres_especiais = df[coluna].apply(lambda x: bool(caracteres_especiais.search(x) if isinstance(x, str) else False)).any()\n",
    "            if contem_caracteres_especiais:\n",
    "                indices_com_caracteres_especiais = df[coluna][df[coluna].apply(lambda x: bool(caracteres_especiais.search(x) if isinstance(x, str) else False))].index.tolist()\n",
    "                colunas_com_caracteres_especiais[coluna] = indices_com_caracteres_especiais\n",
    "\n",
    "    # Exibe o resultado sobre caracteres especiais\n",
    "    print(\"\\n\\nExistem caracteres especiais nas colunas:\", bool(colunas_com_caracteres_especiais))\n",
    "    if colunas_com_caracteres_especiais:\n",
    "        print(\"\\nColunas com caracteres especiais e os índices:\")\n",
    "        for coluna, indices in colunas_com_caracteres_especiais.items():\n",
    "            print(f\"\\n Coluna [ {coluna} ]: Índices com caracteres especiais {indices}\")\n",
    "    else:\n",
    "        print(\"\\nNenhuma coluna possui caracteres especiais.\")\n",
    "\n",
    "print('A função foi criada com sucesso.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792be9a3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Transformando dados carregados em RDD para dataframe do Pandas (apenas para Análise Inicial)\n",
    "\n",
    "- Vamos realizar análise exploratória através da função acima. RDDs são ótimos para processamento, mas ruins para exploração, então converteremos o RDD para DataFrame Spark e então para DataFrame Pandas (**não é possível converter diretamente objeto RDD para objeto Pandas**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte RDD para DataFrame Spark, corrigindo a separação de colunas\n",
    "header = spamRDD.first().replace('\"', '').split(';')\n",
    "df_spark_com_cabecalho = spamRDD.map(lambda x: x.replace('\"', '').split(';')).toDF(header)\n",
    "\n",
    "# Remover a primeira linha do DataFrame, que é o cabeçalho\n",
    "df_spark_com_cabecalho = df_spark_com_cabecalho.filter(df_spark_com_cabecalho[header[0]] != header[0])\n",
    "\n",
    "# Verificar o tipo do objeto\n",
    "print(type(df_spark_com_cabecalho), '\\n')\n",
    "\n",
    "# Converte DataFrame Spark para DataFrame Pandas\n",
    "df_pandas = df_spark_com_cabecalho.toPandas()\n",
    "\n",
    "# Visualizando as primeiras linhas do DataFrame Pandas\n",
    "display(df_pandas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c67f4a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Visualizando Função para Análise Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f247874",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_analise_inicial(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491c278",
   "metadata": {},
   "source": [
    "### Resumo\n",
    "\n",
    "- \n",
    "\n",
    "<br> <br> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86703e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
